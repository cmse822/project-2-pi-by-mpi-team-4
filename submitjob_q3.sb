#!/bin/bash --login
# Job name:
#SBATCH --job-name=mpi-parallel

# Number of nodes
#SBATCH --nodes=1

# Number of tasks to run on each node
#SBATCH --ntasks-per-node=4

# Memory per Node
# Specify "M" or "G" for MB and GB respectively
#SBATCH --mem=2G

# Wall time
# Format: "minutes", "hours:minutes:seconds", 
# "days-hours", or "days-hours:minutes"
#SBATCH --time=01:00:00

# Standard output and error to file
# %x: job name, %j: job ID
#SBATCH --output=%x-%j.SLURMout

# Purge current modules and load those we require
module purge
module load GCC/10.3.0 OpenMPI/4.1.1

# Run our job
csv_file_name='Q3.csv'

rounds=(16 64 128 256)
processors=(1 2 3 4)

for i in {1..3}; do
    for r in "${rounds[@]}"; do
        for p in "${processors[@]}"; do
            srun -n $p par_pi_q3.exe $r $csv_file_name
        done
    done
done

# Print resource information
scontrol show job $SLURM_JOB_ID
js -j $SLURM_JOB_ID